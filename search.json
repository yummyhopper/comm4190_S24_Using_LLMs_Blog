[
  {
    "objectID": "posts/002_gpt-4-0125-preview_and_laziness/index.html",
    "href": "posts/002_gpt-4-0125-preview_and_laziness/index.html",
    "title": "ChatGPT Got Less Lazy? Open AI‚Äôs Newest Model: gpt-4-0125-preview",
    "section": "",
    "text": "ChatGPT Got Less Lazy? Open AI‚Äôs Newest Model: gpt-4-0125-preview\n\nOn January 25, 2024 OpenAI released it‚Äôs latest and most advanced GPT model to date intended to compete with Google‚Äôs Gemini.\n\n\n‚ÄúThis model completes tasks like code generation more thoroughly than the previous preview model and is intended to reduce cases of ‚Äúlaziness‚Äù where the model doesn‚Äôt complete a task. The new model also includes the fix for the bug impacting non-English UTF-8 generations.‚Äù\n\n\nHow can AI be lazy?\nWhen we think next gen AI images of eating pizza rolls and binging Game of Thrones aren‚Äôt what comes to mind‚Ä¶ but why not? In a december tweet OpenAI acknowledged the issue:\n\n‚ÄúWe‚Äôve heard all your feedback about GPT4 getting lazier! we haven‚Äôt updated the model since Nov 11th, and this certainly isn‚Äôt intentional. model behavior can be unpredictable, and we‚Äôre looking into fixing it.‚Äù\n\nBut anyone who‚Äôs used ChatGPT has inevitably run into this issue. It‚Äôs that keyboard banging moment when you ask it to sort a CSV or write Python code and it might returns a long explanation of how that could be done and recommend the user try to do it themselves. Annoying!\n\n\nWas GPT 3.5 better at this?\nYes! When I asked each model: ‚ÄúCreate a spreadheet for my taxes‚Äù This is what they returned:\n\n&lt;img src=\"gpt-3.5_example.jpg\" width=\"400\" height=\"400\" /&gt;\n&lt;img src=\"gpt-4_example.jpg\" width=\"400\" height=\"400\" /&gt;\ni\nSo is the newest edition really better? We‚Äôll have to wait and see as it‚Äôs currently only available throught API.\n\n\nSo what can we conclude?\nThe problem of AI laziness is really a problem of human laziness, but one that developers have to account for. With a little more effortful prompting it would not be difficult for any of the models to deliver an optimal result, but that‚Äôs not the AI dream for many users. We are cognitive misers with brains designed to search for solutions that minimize effort while maximizing results, but we don‚Äôt want our AI systems to behave the same way. Rather OpenAI‚Äôs common user wants to give the least possible input and receive a maximally polished result. This means creating action oriented models designed to interpret simple prompts and infer several layers of extrapolation and nuance to deliver the desired result. Whether frontier AI companies choose to cater to the laziness of the mass rather than creating more nuanced and specialized systems that produce higher quality responses to higher quality prompts can be debated. What‚Äôs became clear from this dilemma is that there‚Äôs more that goes into a general purpose model than how well it scores on an SAT, the sheer size of its context window, or its fancy new name. To quote Janet Jackson ‚ÄúWhat have you done for me lately?‚Äù The most commercially viable AI systems will tend towards prioritizing user experience, whether that comes at the expense of accuracy or another measure remains to be seen."
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "A test post 3\n\n\n \n\n\nMax's Dog\n\nsnickers\n\n\n \n\nAn example post from a Jupyter notebook\n\n\n\n`Feb 7, 2024`{=html}\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT Got Less Lazy? Open AI‚Äôs Newest Model: gpt-4-0125-preview\n\n\n\n\n\n\nLLMs\n\n\nChatGPT\n\n\nLaziness\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/001_my_first_post/index.html",
    "href": "posts/001_my_first_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "for idx in range (10):\n    print('hello')\n\nhello\nhello\nhello\nhello\nhello\nhello\nhello\nhello\nhello\nhello"
  },
  {
    "objectID": "posts/001_my_first_post/index.html#this-is-a-blog-post",
    "href": "posts/001_my_first_post/index.html#this-is-a-blog-post",
    "title": "A test post",
    "section": "",
    "text": "for idx in range (10):\n    print('hello')\n\nhello\nhello\nhello\nhello\nhello\nhello\nhello\nhello\nhello\nhello"
  }
]